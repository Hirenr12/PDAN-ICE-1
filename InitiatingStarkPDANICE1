{"cells":[{"cell_type":"markdown","metadata":{"id":"duI4ZCCix55U"},"source":["Install Spark and Java"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9NruWQ2v08X"},"outputs":[],"source":["!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n","!tar xf spark-3.5.0-bin-hadoop3.tgz\n","!pip install -q findspark kaggle"]},{"cell_type":"markdown","metadata":{"id":"JJEM7q_N03Rv"},"source":["Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rK3Y08hsz0EJ"},"outputs":[],"source":["import os\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, year, count, desc,split, explode\n","import matplotlib.pyplot as plt\n","import findspark"]},{"cell_type":"markdown","metadata":{"id":"uFRG1siRx4_G"},"source":["Set Environment Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-i5n5pBz-sV"},"outputs":[],"source":["os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\""]},{"cell_type":"markdown","metadata":{"id":"v6pbh1Cb9X-4"},"source":["**Initialise Spark Session**\n","\n","Sparksession is the entry point to Spark functionality in python (PySpark). We will create a Spark application called \"Netflix Spark-Activity\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FHJLvPtAZMJ"},"outputs":[],"source":["findspark.init()\n","spark = SparkSession.builder.appName(\"Amazon-Review-Activity\").getOrCreate()\n","spark"]},{"cell_type":"markdown","metadata":{"id":"RY7IgHlFAuPA"},"source":["**Load Dataset into Spark**\n","\n","We can use the colab upload feature if needed, or cancel and upload to files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HI45Oy3H-u3i"},"outputs":[],"source":["from google.colab import files\n","uploaded = files.upload()"]},{"cell_type":"markdown","source":[],"metadata":{"id":"NwC5ai0paZHR"}},{"cell_type":"code","source":["df = spark.read.csv(\"output.csv\", header=True, inferSchema=True)\n","df.printSchema()\n","df.show()"],"metadata":{"id":"bYO3ZjK3Z0gR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["EDA"],"metadata":{"id":"KtKBKoGV_FgH"}},{"cell_type":"code","source":["print(\"Total rows:\", df.count())\n","\n","print(\"Columns:\", df.columns)"],"metadata":{"id":"lMggdqA_-4go"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1ZjUQUq5KXiCJIkJehocp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}